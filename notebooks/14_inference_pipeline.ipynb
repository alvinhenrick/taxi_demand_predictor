{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T21:19:44.731316Z",
     "start_time": "2023-05-26T21:19:44.728431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_date=Timestamp('2023-05-26 21:00:00')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "current_date = pd.to_datetime(datetime.utcnow()).floor('H') # - timedelta(hours=1)\n",
    "print(f'{current_date=}')\n",
    "# current_date = pd.Timestamp('2023-02-28 09:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T21:20:24.475853Z",
     "start_time": "2023-05-26T21:19:45.677763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/49323\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Fetching data from 2023-04-28 21:00:00 to 2023-05-26 20:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No training dataset version was provided to initialise batch scoring . Defaulting to version 1.\n",
      "DeprecationWarning: ssl.PROTOCOL_TLS is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-26 14:19:52,306 INFO: USE `taxi_demand_alvin_featurestore`\n",
      "2023-05-26 14:19:52,767 INFO: SELECT `fg0`.`pickup_hour` `pickup_hour`, `fg0`.`rides` `rides`, `fg0`.`pickup_location_id` `pickup_location_id`\n",
      "FROM `taxi_demand_alvin_featurestore`.`time_series_hourly_feature_group_1` `fg0`\n",
      "WHERE `fg0`.`pickup_hour` >= TIMESTAMP '2023-04-27 09:00:00.000' AND `fg0`.`pickup_hour` <= TIMESTAMP '2023-05-27 08:00:00.000'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n"
     ]
    }
   ],
   "source": [
    "from src.inference import load_batch_of_features_from_store\n",
    "\n",
    "features = load_batch_of_features_from_store(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T21:20:29.298629Z",
     "start_time": "2023-05-26T21:20:24.476884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/49323\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/49323/modelregistries/49323/models/taxi_demand_predictor_next_hour_2). Server response: \nHTTP code: 404, HTTP reason: Not Found, error code: 360000, error msg: No model found for provided name and version., user msg: ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRestAPIError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minference\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      2\u001B[0m     load_model_from_registry,\n\u001B[1;32m      3\u001B[0m     get_model_predictions\n\u001B[1;32m      4\u001B[0m )\n\u001B[0;32m----> 6\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model_from_registry\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m predictions \u001B[38;5;241m=\u001B[39m get_model_predictions(model, features)\n",
      "File \u001B[0;32m~/PycharmProjects/taxi_demand_predictor/src/inference.py:105\u001B[0m, in \u001B[0;36mload_model_from_registry\u001B[0;34m()\u001B[0m\n\u001B[1;32m    102\u001B[0m project \u001B[38;5;241m=\u001B[39m get_hopsworks_project()\n\u001B[1;32m    103\u001B[0m model_registry \u001B[38;5;241m=\u001B[39m project\u001B[38;5;241m.\u001B[39mget_model_registry()\n\u001B[0;32m--> 105\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMODEL_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mversion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMODEL_VERSION\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \n\u001B[1;32m    110\u001B[0m model_dir \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mdownload()\n\u001B[1;32m    111\u001B[0m model \u001B[38;5;241m=\u001B[39m joblib\u001B[38;5;241m.\u001B[39mload(Path(model_dir)  \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/taxi_demand_predictor/.venv/lib/python3.10/site-packages/hsml/model_registry.py:85\u001B[0m, in \u001B[0;36mModelRegistry.get_model\u001B[0;34m(self, name, version)\u001B[0m\n\u001B[1;32m     77\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m     78\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo version provided for getting model `\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m`, defaulting to `\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m     79\u001B[0m             name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mDEFAULT_VERSION\n\u001B[1;32m     80\u001B[0m         ),\n\u001B[1;32m     81\u001B[0m         util\u001B[38;5;241m.\u001B[39mVersionWarning,\n\u001B[1;32m     82\u001B[0m     )\n\u001B[1;32m     83\u001B[0m     version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mDEFAULT_VERSION\n\u001B[0;32m---> 85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_model_api\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43mversion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_registry_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshared_registry_project_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshared_registry_project_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/taxi_demand_predictor/.venv/lib/python3.10/site-packages/hsml/core/model_api.py:75\u001B[0m, in \u001B[0;36mModelApi.get\u001B[0;34m(self, name, version, model_registry_id, shared_registry_project_name)\u001B[0m\n\u001B[1;32m     65\u001B[0m path_params \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproject\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     67\u001B[0m     _client\u001B[38;5;241m.\u001B[39m_project_id,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     71\u001B[0m     name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(version),\n\u001B[1;32m     72\u001B[0m ]\n\u001B[1;32m     73\u001B[0m query_params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpand\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrainingdatasets\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m---> 75\u001B[0m model_json \u001B[38;5;241m=\u001B[39m \u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m model_meta \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mModel\u001B[38;5;241m.\u001B[39mfrom_response_json(model_json)\n\u001B[1;32m     78\u001B[0m model_meta\u001B[38;5;241m.\u001B[39mshared_registry_project_name \u001B[38;5;241m=\u001B[39m shared_registry_project_name\n",
      "File \u001B[0;32m~/PycharmProjects/taxi_demand_predictor/.venv/lib/python3.10/site-packages/hsml/decorators.py:35\u001B[0m, in \u001B[0;36mconnected.<locals>.if_connected\u001B[0;34m(inst, *args, **kwargs)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inst\u001B[38;5;241m.\u001B[39m_connected:\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NoHopsworksConnectionError\n\u001B[0;32m---> 35\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/taxi_demand_predictor/.venv/lib/python3.10/site-packages/hsml/client/base.py:108\u001B[0m, in \u001B[0;36mClient._send_request\u001B[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001B[0m\n\u001B[1;32m    105\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_session\u001B[38;5;241m.\u001B[39msend(prepped, verify\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_verify, stream\u001B[38;5;241m=\u001B[39mstream)\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m--> 108\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mRestAPIError(url, response)\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "\u001B[0;31mRestAPIError\u001B[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/49323/modelregistries/49323/models/taxi_demand_predictor_next_hour_2). Server response: \nHTTP code: 404, HTTP reason: Not Found, error code: 360000, error msg: No model found for provided name and version., user msg: "
     ]
    }
   ],
   "source": [
    "from src.inference import (\n",
    "    load_model_from_registry,\n",
    "    get_model_predictions\n",
    ")\n",
    "\n",
    "model = load_model_from_registry()\n",
    "predictions = get_model_predictions(model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['pickup_hour'] = current_date\n",
    "predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save these predictions in the feature store, so they can be later consumed by our Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_store_api import get_feature_store\n",
    "import src.config as config\n",
    "\n",
    "# connect to the feature group\n",
    "feature_group = get_feature_store().get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_MODEL_PREDICTIONS,\n",
    "    version=1,\n",
    "    description=\"Predictions generate by our production model\",\n",
    "    primary_key = ['pickup_location_id', 'pickup_hour'],\n",
    "    event_time='pickup_hour',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group.insert(predictions, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b98d97558a062384a76b0309256306c9ce5dd4e2074fe66c33532239207fc923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
